{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b324bf9",
   "metadata": {},
   "source": [
    "# üìì LoRA Evaluation Notebook for Seq2Seq Models (Apple M1/M2/M3 Friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eabe71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from peft import PeftModelForSeq2SeqLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9080074c",
   "metadata": {},
   "source": [
    "# ‚úÖ Choose your model and LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38375313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"google/flan-t5-small\"\n",
    "lora_path = \"./lora-output\"  # Or set to None if not using LoRA\n",
    "prompt = \"What is the chemical formula for water?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a957cf",
   "metadata": {},
   "source": [
    "# Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2781464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading tokenizer and model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üîÑ Loading tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d151ab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîå Applying LoRA adapter from: ./lora-output\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at './lora-output'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHFValidationError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlx-m1/lib/python3.11/site-packages/peft/config.py:260\u001b[39m, in \u001b[36mPeftConfigMixin._get_peft_type\u001b[39m\u001b[34m(cls, model_id, **hf_hub_download_kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     config_file = \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhf_hub_download_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlx-m1/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:106\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mrepo_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfrom_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mto_id\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg_name == \u001b[33m\"\u001b[39m\u001b[33mtoken\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlx-m1/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:160\u001b[39m, in \u001b[36mvalidate_repo_id\u001b[39m\u001b[34m(repo_id)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX.match(repo_id):\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRepo id must use alphanumeric chars or \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m--\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m\u001b[33m are\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m forbidden, \u001b[39m\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\u001b[33m cannot start or end the name, max length is 96:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    163\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    164\u001b[39m     )\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[31mHFValidationError\u001b[39m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './lora-output'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lora_path:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîå Applying LoRA adapter from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlora_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     model = \u001b[43mPeftModelForSeq2SeqLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Tokenize prompt\u001b[39;00m\n\u001b[32m      7\u001b[39m inputs = tokenizer(prompt, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlx-m1/lib/python3.11/site-packages/peft/peft_model.py:439\u001b[39m, in \u001b[36mPeftModel.from_pretrained\u001b[39m\u001b[34m(cls, model, model_id, adapter_name, is_trainable, config, autocast_adapter_dtype, ephemeral_gpu_offload, low_cpu_mem_usage, **kwargs)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# load the config\u001b[39;00m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    438\u001b[39m     config = PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m         \u001b[43mPeftConfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_peft_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msubfolder\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrevision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcache_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muse_auth_token\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoken\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m     ].from_pretrained(model_id, **kwargs)\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PeftConfig):\n\u001b[32m    449\u001b[39m     config.inference_mode = \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/mlx-m1/lib/python3.11/site-packages/peft/config.py:266\u001b[39m, in \u001b[36mPeftConfigMixin._get_peft_type\u001b[39m\u001b[34m(cls, model_id, **hf_hub_download_kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m         config_file = hf_hub_download(\n\u001b[32m    261\u001b[39m             model_id,\n\u001b[32m    262\u001b[39m             CONFIG_NAME,\n\u001b[32m    263\u001b[39m             **hf_hub_download_kwargs,\n\u001b[32m    264\u001b[39m         )\n\u001b[32m    265\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCan\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m at \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    268\u001b[39m loaded_attributes = \u001b[38;5;28mcls\u001b[39m.from_json_file(config_file)\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_attributes[\u001b[33m\"\u001b[39m\u001b[33mpeft_type\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Can't find 'adapter_config.json' at './lora-output'"
     ]
    }
   ],
   "source": [
    "# Apply LoRA if provided\n",
    "if lora_path:\n",
    "    print(f\"üîå Applying LoRA adapter from: {lora_path}\")\n",
    "    model = PeftModelForSeq2SeqLM.from_pretrained(model, lora_path)\n",
    "\n",
    "# Tokenize prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output\n",
    "print(\"‚ö° Generating response...\")\n",
    "start = time.time()\n",
    "outputs = model.generate(input_ids=inputs.input_ids, max_new_tokens=50)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"\\nüó®Ô∏è  Response:\", response)\n",
    "print(f\"‚è±Ô∏è  Latency: {end - start:.3f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cb293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model size\n",
    "size_mb = round(sum(p.numel() * p.element_size() for p in model.parameters()) / 1e6, 2)\n",
    "print(f\"üì¶ Approx model size: {size_mb} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
